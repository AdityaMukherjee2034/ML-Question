{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f5b0b9",
   "metadata": {},
   "source": [
    "Installing neseccary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c28fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==2.17.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (4.64.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (0.23.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from datasets==2.17.0) (6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from aiohttp->datasets==2.17.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\91758\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.17.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from pandas->datasets==2.17.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from pandas->datasets==2.17.0) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91758\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.17.0) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in c:\\users\\91758\\anaconda3\\lib\\site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets==2.17.0\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0654c9",
   "metadata": {},
   "source": [
    "Importing necessary items and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ecf8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "930692c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5994a7",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dbcd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news.article.json', 'r', encoding='utf-8') as file:\n",
    "    articles = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8d285",
   "metadata": {},
   "source": [
    "Initiating the t-5 model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bf36729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91758\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b07dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321ba29",
   "metadata": {},
   "source": [
    "Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ccb0d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text.lower()\n",
    "\n",
    "keywords = [\n",
    "    \"Hamas\", \"Jersalem\", \"Palestine\", \"israel\", \"Gaza\", \"attack\", \"war\"\n",
    "]\n",
    "# Filter articles that have 'content' and match any of the keywords\n",
    "filtered_articles = []\n",
    "for article in articles:\n",
    "        if any(keyword in article[\"articleBody\"] for keyword in keywords) :\n",
    "            filtered_articles.append(article)\n",
    "        \n",
    "# Filter articles that have 'content' and match any of the keywords\n",
    "\n",
    "# Clean the articles\n",
    "cleaned_articles = [\n",
    "    {'title': clean_text(article.get('title', '')), 'content': clean_text(article['articleBody'])} \n",
    "    for article in filtered_articles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b973f5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27098"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec704f",
   "metadata": {},
   "source": [
    "Defining various functions to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b96308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(question, context):\n",
    "    \n",
    "    return f\"answer the following question based on the context: {question} context: {context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a9458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, context, model, tokenizer, max_length=512, temperature=0.1):\n",
    "    input_text = prepare_input(question, context)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_length=max_length, \n",
    "        num_return_sequences=1, \n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f73bf149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Israel\n"
     ]
    }
   ],
   "source": [
    "# Combine the content of all cleaned articles for context\n",
    "combined_context = \"\".join(article.get('articleBody', \"\") for article in cleaned_articles)\n",
    "\n",
    "# Define the question\n",
    "question = \" hamas vs israel?\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = generate_answer(question, combined_context, model, tokenizer)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6efe188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
